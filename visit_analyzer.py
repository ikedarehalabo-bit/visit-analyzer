import streamlit as st
import pandas as pd
import unicodedata
import re
import time
from io import BytesIO

# ---------------------------------------------------------
# 1. å…±é€šé–¢æ•° & è¨­å®š
# ---------------------------------------------------------
def normalize_and_extract_minutes(text):
    if pd.isna(text): return None, None
    text_norm = unicodedata.normalize('NFKC', str(text))
    match = re.search(r'(\d+)', text_norm)
    if match: return int(match.group(1)), text_norm
    return None, text_norm

def extract_job_title(name_str):
    if pd.isna(name_str): return ""
    match = re.search(r'[ï¼ˆ\(](.*?)[ï¼‰\)]', str(name_str))
    if match: return match.group(1).strip()
    return "ä¸æ˜"

def is_emergency(service_content):
    if pd.isna(service_content): return False
    return "ç·Š" in str(service_content) or "ç·Šæ€¥" in str(service_content)

def navigate_to(page):
    st.session_state.current_page = page
    st.rerun()

def load_file_content(file):
    results = []
    if file.name.endswith('.xlsx'):
        try:
            xls = pd.read_excel(file, sheet_name=None, header=None)
            for sname, df in xls.items(): results.append((df, f"{file.name}[{sname}]"))
        except Exception as e: return [], str(e)
    else:
        try:
            df = pd.read_csv(file, header=None)
            results.append((df, file.name))
        except Exception as e: return [], str(e)
    return results, None

def parse_single_dataframe(df_raw, source_name):
    try:
        lines_df = df_raw.fillna("").astype(str)
        # æœ€ä½é™ã®è¡Œæ•°ãƒã‚§ãƒƒã‚¯
        if len(lines_df) < 2: return [], "ãƒ‡ãƒ¼ã‚¿è¡Œä¸è¶³"
        
        # A2ã‚»ãƒ«(ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹1,0)ä»˜è¿‘ã«ã‚ã‚‹æ°åã‚’å–å¾—ãƒˆãƒ©ã‚¤
        full_name = lines_df.iloc[1, 0].strip()
        if not full_name: return [], "æ°åæ¬„(A2)ãŒç©ºæ¬„"

        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¢ç´¢
        header_row_idx = -1
        for idx, row in lines_df.iterrows():
            row_str = " ".join(row.values)
            if "è¨ªå•æ—¥" in row_str and "Sæä¾›æ™‚é–“" in row_str:
                header_row_idx = idx
                break
        if header_row_idx == -1: return [], "ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œãªã—"

        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        df_data = df_raw.iloc[header_row_idx + 1:].copy()
        df_data.columns = [str(c).strip() for c in df_raw.iloc[header_row_idx].values]
        
        required = ['è¨ªå•æ—¥', 'Sæä¾›æ™‚é–“', 'ã‚µãƒ¼ãƒ“ã‚¹å†…å®¹', 'ä¿é™ºé©ç”¨']
        missing = [c for c in required if c not in df_data.columns]
        if missing: return [], f"å¿…é ˆåˆ—ä¸è¶³: {','.join(missing)}"

        job_title = extract_job_title(full_name)
        records = []
        target_mins = [20, 30, 40, 60, 90]

        for _, row in df_data.iterrows():
            try:
                v_date = pd.to_datetime(row['è¨ªå•æ—¥'])
                if pd.isna(v_date): continue
            except: continue

            minute, _ = normalize_and_extract_minutes(row['Sæä¾›æ™‚é–“'])
            mins = minute if minute else 0
            ins = "åŒ»ç™‚" if "åŒ»ç™‚" in str(row['ä¿é™ºé©ç”¨']) else ("ä»‹è­·" if "ä»‹è­·" in str(row['ä¿é™ºé©ç”¨']) else "ãã®ä»–")
            cat_min = f"{mins}åˆ†" if mins in target_mins else "ãã®ä»–æ™‚é–“"
            
            records.append({
                'æ°å': full_name, 'è·ç¨®': job_title, 'è¨ªå•æ—¥': v_date,
                'æ™‚é–“(åˆ†)': mins, 'ä¿é™º': ins, 'ã‚«ãƒ†ã‚´ãƒª': f"{cat_min}ï¼ˆ{ins}ï¼‰",
                'ã‚µãƒ¼ãƒ“ã‚¹å†…å®¹': row['ã‚µãƒ¼ãƒ“ã‚¹å†…å®¹'], 'ç·Šæ€¥ãƒ•ãƒ©ã‚°': is_emergency(row['ã‚µãƒ¼ãƒ“ã‚¹å†…å®¹']),
                'å…ƒãƒ•ã‚¡ã‚¤ãƒ«': source_name
            })
        return records, None
    except Exception as e: return [], str(e)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="VISIT ANALYZER Lite", layout="wide", page_icon="âš¡")
st.set_page_config(page_title="VISIT ANALYZER Lite", layout="wide", page_icon="âš¡")
st.markdown('<meta name="google" content="notranslate">', unsafe_allow_html=True)

if 'first_load' not in st.session_state: st.session_state.first_load = True
if 'current_page' not in st.session_state: st.session_state.current_page = "HOME"
if 'master_df' not in st.session_state: st.session_state.master_df = pd.DataFrame()

# ---------------------------------------------------------
# 2. CSS & ãƒ‡ã‚¶ã‚¤ãƒ³å®šç¾©
# ---------------------------------------------------------
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@700;900&family=Noto+Sans+JP:wght@400;700&display=swap');
    .stApp { background-color: #050505; color: #e0e0e0; font-family: 'Noto Sans JP', sans-serif; }
    h1, h2, h3 { font-family: 'Montserrat', 'Noto Sans JP'; color: #ffffff; text-transform: uppercase; }
    h1 { text-shadow: 0 0 15px #00FF41; }
    .stButton>button { background: #000; color: #00FF41; border: 1px solid #00FF41; font-weight: bold; width: 100%; }
    .stButton>button:hover { background: #00FF41; color: #000; }
    
    #intro-overlay {
        position: fixed; top: 0; left: 0; width: 100vw; height: 100vh; background: #000; z-index: 9999;
        display: flex; justify-content: center; align-items: center; animation: fadeOutOverlay 2.5s forwards; pointer-events: none;
    }
    #intro-logo { font-family: 'Montserrat', sans-serif; font-size: 3rem; color: #00FF41; opacity: 0; animation: popInLogo 2s forwards; }
    @keyframes popInLogo { 0% { opacity: 0; transform: scale(0.8); } 50% { opacity: 1; transform: scale(1.1); } 100% { opacity: 0; transform: scale(1.5); } }
    @keyframes fadeOutOverlay { 0% { opacity: 1; } 80% { opacity: 1; } 100% { opacity: 0; visibility: hidden; } }
</style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# 3. èµ·å‹•ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
# ---------------------------------------------------------
if st.session_state.first_load:
    st.markdown('<div id="intro-overlay"><div id="intro-logo">VISIT ANALYZER Lite</div></div>', unsafe_allow_html=True)
    time.sleep(2.0)
    st.session_state.first_load = False

# ---------------------------------------------------------
# 4. ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ---------------------------------------------------------
st.title("VISIT ANALYZER Lite")

# --- HOME ---
if st.session_state.current_page == "HOME":
    st.markdown("#### ã‚·ãƒ³ãƒ—ãƒ«è¨ªå•é›†è¨ˆãƒ„ãƒ¼ãƒ«")
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (UPLOAD)", use_container_width=True): navigate_to("UPLOAD")
    with c2:
        if st.button("ğŸ“Š é›†è¨ˆãƒ¬ãƒãƒ¼ãƒˆ (REPORTS)", use_container_width=True): navigate_to("REPORTS")

else:
    # --- HEADER ---
    col_head1, col_head2 = st.columns([9, 1])
    with col_head1:
        titles = {"UPLOAD": "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿", "REPORTS": "é›†è¨ˆãƒ¬ãƒãƒ¼ãƒˆ"}
        st.markdown(f"### :: {titles.get(st.session_state.current_page, '')}")
    with col_head2:
        if st.button("âœ•", key="close_main"): navigate_to("HOME")

    # --- UPLOAD ---
    if st.session_state.current_page == "UPLOAD":
        st.info("å®Ÿç¸¾ç°¿ (CSV/Excel) ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚")
        uploaded_files = st.file_uploader("", type=['csv', 'xlsx'], accept_multiple_files=True)
        
        if uploaded_files:
            all_recs = []
            bar = st.progress(0)
            for i, f in enumerate(uploaded_files):
                d_list, err = load_file_content(f)
                if not err:
                    for df_raw, src in d_list:
                        recs, perr = parse_single_dataframe(df_raw, src)
                        if recs: all_recs.extend(recs)
                bar.progress((i+1)/len(uploaded_files))
            
            if all_recs:
                st.session_state.master_df = pd.DataFrame(all_recs)
                st.success(f"{len(all_recs)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
            else:
                st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    # --- REPORTS ---
    elif st.session_state.current_page == "REPORTS":
        if not st.session_state.master_df.empty:
            df = st.session_state.master_df.copy()
            names = sorted(df['æ°å'].unique())
            sel = st.multiselect("ã‚¹ã‚¿ãƒƒãƒ•çµã‚Šè¾¼ã¿:", names, default=names)
            
            if sel:
                df = df[df['æ°å'].isin(sel)]
                t1, t2 = st.tabs(["æ—¥æ¬¡ãƒ»é€±æ¬¡", "æœˆé–“ã‚µãƒãƒªãƒ¼"])
                
                with t1:
                    m = st.radio("è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰", ["æ—¥æ¬¡", "é€±æ¬¡"], horizontal=True)
                    if m == "æ—¥æ¬¡":
                        p = df.pivot_table(index=['æ°å', 'è·ç¨®', 'è¨ªå•æ—¥'], columns='ã‚«ãƒ†ã‚´ãƒª', aggfunc='size', fill_value=0)
                        p['åˆè¨ˆ'] = p.sum(axis=1)
                        st.dataframe(p.style.background_gradient(cmap='Greens', subset=['åˆè¨ˆ']), use_container_width=True)
                    else:
                        df['é€±'] = df['è¨ªå•æ—¥'] - pd.to_timedelta(df['è¨ªå•æ—¥'].dt.weekday, unit='D')
                        p = df.pivot_table(index=['æ°å', 'è·ç¨®', 'é€±'], columns='ã‚«ãƒ†ã‚´ãƒª', aggfunc='size', fill_value=0)
                        p['åˆè¨ˆ'] = p.sum(axis=1)
                        st.dataframe(p.style.format({"é€±": "{:%Y-%m-%d}"}).background_gradient(cmap='Greens', subset=['åˆè¨ˆ']), use_container_width=True)
                
                with t2:
                    df['æœˆ'] = df['è¨ªå•æ—¥'].dt.strftime('%Y-%m')
                    p = df.pivot_table(index=['æ°å', 'è·ç¨®', 'æœˆ'], columns='ã‚«ãƒ†ã‚´ãƒª', aggfunc='size', fill_value=0)
                    p['åˆè¨ˆ'] = p.sum(axis=1)
                    st.dataframe(p.style.background_gradient(cmap='Greens', subset=['åˆè¨ˆ']), use_container_width=True)
            else:
                st.warning("ã‚¹ã‚¿ãƒƒãƒ•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:

            st.error("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
